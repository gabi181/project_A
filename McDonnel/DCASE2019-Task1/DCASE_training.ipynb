{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a GPU\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librosa version =  0.8.0\n",
      "Pysoundfile version =  0.10.3\n",
      "keras version =  2.4.3\n",
      "tensorflow version =  2.2.0\n"
     ]
    }
   ],
   "source": [
    "#imports \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import soundfile as sound\n",
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from DCASE2019_network import model_resnet\n",
    "from DCASE_training_functions import LR_WarmRestart, MixupGenerator\n",
    "\n",
    "print(\"Librosa version = \",librosa.__version__)\n",
    "print(\"Pysoundfile version = \",sound.__version__)\n",
    "print(\"keras version = \",keras.__version__)\n",
    "print(\"tensorflow version = \",tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WhichTask = '1a'\n",
    "WhichTask = '1b'\n",
    "#WhichTask = '1c'\n",
    "\n",
    "if WhichTask =='1a':\n",
    "    ThisPath = '../TAU-urban-acoustic-scenes-2019-development/'\n",
    "    TrainFile = ThisPath + 'evaluation_setup/fold1_train.csv'\n",
    "    ValFile = ThisPath + 'evaluation_setup/fold1_evaluate.csv'\n",
    "    sr = 48000\n",
    "    num_audio_channels = 2\n",
    "elif WhichTask =='1b':\n",
    "    ThisPath = '../Task1b/'\n",
    "    TrainFile = ThisPath + 'evaluation_setup/fold1_train.csv'\n",
    "    ValFile = ThisPath + 'evaluation_setup/fold1_evaluate.csv'\n",
    "    sr = 44100\n",
    "    num_audio_channels = 1\n",
    "elif WhichTask =='1c':\n",
    "    ThisPath = '../Task1c/'\n",
    "    TrainFile = ThisPath + 'evaluation_setup/fold1_train.csv'\n",
    "    sr = 44100\n",
    "    num_audio_channels = 1\n",
    "    \n",
    "SampleDuration = 10\n",
    "\n",
    "#log-mel spectrogram parameters\n",
    "NumFreqBins = 128\n",
    "NumFFTPoints = 2048\n",
    "HopLength = int(NumFFTPoints/2)\n",
    "NumTimeBins = int(np.ceil(SampleDuration*sr/HopLength))\n",
    "\n",
    "#training parameters\n",
    "max_lr = 0.1\n",
    "batch_size = 32\n",
    "num_epochs = 510\n",
    "mixup_alpha = 0.4\n",
    "crop_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load filenames and labels\n",
    "dev_train_df = pd.read_csv(TrainFile,sep='\\t', encoding='ASCII')\n",
    "dev_val_df = pd.read_csv(ValFile,sep='\\t', encoding='ASCII')\n",
    "wavpaths_train = dev_train_df['filename'].tolist()\n",
    "wavpaths_val = dev_val_df['filename'].tolist()\n",
    "y_train_labels =  dev_train_df['scene_label'].astype('category').cat.codes.values\n",
    "y_val_labels =  dev_val_df['scene_label'].astype('category').cat.codes.values\n",
    "\n",
    "ClassNames = np.unique(dev_train_df['scene_label'])\n",
    "NumClasses = len(ClassNames)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train_labels, NumClasses)\n",
    "y_val = keras.utils.to_categorical(y_val_labels, NumClasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load wav files and get log-mel spectrograms, deltas, and delta-deltas\n",
    "def deltas(X_in):\n",
    "    X_out = (X_in[:,:,2:,:]-X_in[:,:,:-2,:])/10.0\n",
    "    X_out = X_out[:,:,1:-1,:]+(X_in[:,:,4:,:]-X_in[:,:,:-4,:])/5.0\n",
    "    return X_out\n",
    "\n",
    "LM_train = np.zeros((len(wavpaths_train),NumFreqBins,NumTimeBins,num_audio_channels),'float32')\n",
    "for i in range(len(wavpaths_train)):\n",
    "    stereo,fs = sound.read(ThisPath + wavpaths_train[i],stop=SampleDuration*sr)\n",
    "    for channel in range(num_audio_channels):\n",
    "        if len(stereo.shape)==1:\n",
    "            stereo = np.expand_dims(stereo,-1)\n",
    "        LM_train[i,:,:,channel]= librosa.feature.melspectrogram(stereo[:,channel], \n",
    "                                       sr=sr,\n",
    "                                       n_fft=NumFFTPoints,\n",
    "                                       hop_length=HopLength,\n",
    "                                       n_mels=NumFreqBins,\n",
    "                                       fmin=0.0,\n",
    "                                       fmax=sr/2,\n",
    "                                       htk=True,\n",
    "                                       norm=None)\n",
    "\n",
    "LM_train = np.log(LM_train+1e-8)\n",
    "LM_deltas_train = deltas(LM_train)\n",
    "LM_deltas_deltas_train = deltas(LM_deltas_train)\n",
    "LM_train = np.concatenate((LM_train[:,:,4:-4,:],LM_deltas_train[:,:,2:-2,:],LM_deltas_deltas_train),axis=-1)\n",
    "\n",
    "LM_val = np.zeros((len(wavpaths_val),NumFreqBins,NumTimeBins,num_audio_channels),'float32')\n",
    "for i in range(len(wavpaths_val)):\n",
    "    stereo,fs = sound.read(ThisPath + wavpaths_val[i],stop=SampleDuration*sr)\n",
    "    for channel in range(num_audio_channels):\n",
    "        if len(stereo.shape)==1:\n",
    "            stereo = np.expand_dims(stereo,-1)\n",
    "        LM_val[i,:,:,channel]= librosa.feature.melspectrogram(stereo[:,channel], \n",
    "                                       sr=sr,\n",
    "                                       n_fft=NumFFTPoints,\n",
    "                                       hop_length=HopLength,\n",
    "                                       n_mels=NumFreqBins,\n",
    "                                       fmin=0.0,\n",
    "                                       fmax=sr/2,\n",
    "                                       htk=True,\n",
    "                                       norm=None)\n",
    "\n",
    "LM_val = np.log(LM_val+1e-8)\n",
    "LM_deltas_val = deltas(LM_val)\n",
    "LM_deltas_deltas_val = deltas(LM_deltas_val)\n",
    "LM_val = np.concatenate((LM_val[:,:,4:-4,:],LM_deltas_val[:,:,2:-2,:],LM_deltas_deltas_val),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create and compile the model\n",
    "model = model_resnet(NumClasses,\n",
    "                     input_shape =[NumFreqBins,None,3*num_audio_channels], \n",
    "                     num_filters =24,\n",
    "                     wd=1e-3)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer =SGD(lr=max_lr,decay=0, momentum=0.9, nesterov=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set learning rate schedule\n",
    "lr_scheduler = LR_WarmRestart(nbatch=np.ceil(LM_train.shape[0]/batch_size), Tmult=2,\n",
    "                              initial_lr=max_lr, min_lr=max_lr*1e-4,\n",
    "                              epochs_restart = [3.0, 7.0, 15.0, 31.0, 63.0,127.0,255.0,511.0]) \n",
    "callbacks = [lr_scheduler]\n",
    "\n",
    "#create data generator\n",
    "TrainDataGen = MixupGenerator(LM_train, \n",
    "                              y_train, \n",
    "                              batch_size=batch_size,\n",
    "                              alpha=mixup_alpha,\n",
    "                              crop_length=crop_length)()\n",
    "\n",
    "#train the model\n",
    "history = model.fit_generator(TrainDataGen,\n",
    "                              validation_data=(LM_val, y_val),\n",
    "                              epochs=num_epochs, \n",
    "                              verbose=1, \n",
    "                              workers=4,\n",
    "                              max_queue_size = 100,\n",
    "                              callbacks=callbacks,\n",
    "                              steps_per_epoch=np.ceil(LM_train.shape[0]/batch_size)\n",
    "                              ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('DCASE_' + WhichTask + '_Task_development_1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}